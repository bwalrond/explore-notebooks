{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x11172b450>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line count of train file: 878050\n",
      "Lines in schema file: 9\n",
      "Length of the schemadict: 9\n",
      "Max len: 9\n",
      "Min len: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PythonRDD[222] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "sfcrime_raw_data = '/Users/bill.walrond/Documents/dsprj/data/SanFranCrime/train.csv'\n",
    "sfcrime_schema_file = '/Users/bill.walrond/Documents/dsprj/data/SanFranCrime/train_schema.txt'\n",
    "\n",
    "sfc_rdd = sc.textFile(sfcrime_raw_data)\n",
    "    \n",
    "print 'Line count of train file: %d' % sfc_rdd.count()\n",
    "\n",
    "schemadict = {}\n",
    "i = 0\n",
    "schema = sc.textFile(sfcrime_schema_file)\n",
    "line_cnt = schema.count()\n",
    "print 'Lines in schema file: %d' % line_cnt\n",
    "for l in schema.collect():\n",
    "    col = l.split(',')\n",
    "    schemadict.update({i: (col[0],col[1])})\n",
    "    i += 1\n",
    "print 'Length of the schemadict: %d' % len(schemadict.keys())\n",
    "\n",
    "# Establish the Struct for the Schema\n",
    "keys = schemadict.keys()\n",
    "keys.sort()\n",
    "schema = StructType()\n",
    "for k in keys:\n",
    "    if schemadict[k][1] == 'int':\n",
    "        schema.add(StructField(schemadict[k][0], IntegerType(), True))\n",
    "    elif schemadict[k][1] == 'str':\n",
    "        schema.add(StructField(schemadict[k][0], StringType(), True))\n",
    "    elif schemadict[k][1] == 'float':\n",
    "        schema.add(StructField(schemadict[k][0], FloatType(), True))\n",
    "    elif schemadict[k][1] == 'datetime':\n",
    "        schema.add(StructField(schemadict[k][0], TimestampType(), True))\n",
    "    else:\n",
    "        print 'Unsupported or incorrect data type'\n",
    "\n",
    "# Skip the first header line with this trick ...\n",
    "sfc_nh = sfc_rdd.zipWithIndex().filter(lambda tup: tup[1] > 0).map(lambda tup: tup[0])\n",
    "\n",
    "def toRowSep(line):\n",
    "    \"\"\"Parses one row using csv reader\"\"\"\n",
    "    for r in csv.reader([line], delimiter=','):\n",
    "        return r\n",
    "\n",
    "sfc_split = sfc_nh.map(toRowSep)\n",
    "    \n",
    "lens = sfc_split.map(lambda r: len(r))\n",
    "print 'Max len: %d' % lens.max()\n",
    "print 'Min len: %d' % lens.min()\n",
    "sfc_split.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878049\n"
     ]
    }
   ],
   "source": [
    "def convert_types(row,schema):\n",
    "    d = row\n",
    "    for col, data in enumerate(row):\n",
    "        if col <= len(schema.keys()):\n",
    "            typed = schema[col]\n",
    "            if data is None:\n",
    "                d[col] = None\n",
    "            elif typed[1] == 'string':\n",
    "                d[col] = data\n",
    "            elif typed[1] == 'int':\n",
    "                d[col] = int(round(float(data)))\n",
    "            elif typed[1] == 'float':\n",
    "                d[col] = float(data)\n",
    "            elif typed[1] == 'datetime':\n",
    "                # d[col] = data\n",
    "                # d[col] = dateutil.parser.parse(data)\n",
    "                d[col] = datetime.strptime(data,'%Y-%m-%d %H:%M:%S')\n",
    "    return d\n",
    "\n",
    "def toTypedRow(row):\n",
    "    return convert_types(row, schemadict)\n",
    "\n",
    "# Now, convert the types of all the rdd elements\n",
    "sfc_typed = sfc_split.map(toTypedRow)\n",
    "sfc_typed.take(1)\n",
    "sfc_train = sqlContext.createDataFrame(sfc_typed, schema)\n",
    "print sfc_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Dates: timestamp, Category: string, Descript: string, DayOfWeek: string, PdDistrict: string, Resolution: string, Address: string, X: float, Y: float]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfc_train.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Dates: timestamp (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Descript: string (nullable = true)\n",
      " |-- DayOfWeek: string (nullable = true)\n",
      " |-- PdDistrict: string (nullable = true)\n",
      " |-- Resolution: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- X: float (nullable = true)\n",
      " |-- Y: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sfc_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+---------+----------+--------------+--------------------+-----------+---------+\n",
      "|               Dates|      Category|            Descript|DayOfWeek|PdDistrict|    Resolution|             Address|          X|        Y|\n",
      "+--------------------+--------------+--------------------+---------+----------+--------------+--------------------+-----------+---------+\n",
      "|2015-05-13 23:53:...|      WARRANTS|      WARRANT ARREST|Wednesday|  NORTHERN|ARREST, BOOKED|  OAK ST / LAGUNA ST| -122.42589|37.774597|\n",
      "|2015-05-13 23:53:...|OTHER OFFENSES|TRAFFIC VIOLATION...|Wednesday|  NORTHERN|ARREST, BOOKED|  OAK ST / LAGUNA ST| -122.42589|37.774597|\n",
      "|2015-05-13 23:33:...|OTHER OFFENSES|TRAFFIC VIOLATION...|Wednesday|  NORTHERN|ARREST, BOOKED|VANNESS AV / GREE...| -122.42436|37.800415|\n",
      "|2015-05-13 23:30:...| LARCENY/THEFT|GRAND THEFT FROM ...|Wednesday|  NORTHERN|          NONE|1500 Block of LOM...|-122.426994|37.800873|\n",
      "|2015-05-13 23:30:...| LARCENY/THEFT|GRAND THEFT FROM ...|Wednesday|      PARK|          NONE|100 Block of BROD...|-122.438736| 37.77154|\n",
      "+--------------------+--------------+--------------------+---------+----------+--------------+--------------------+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sfc_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parqFileName = '/Users/bill.walrond/Documents/dsprj/data/SanFranCrime/train.pqt'\n",
    "sfc_train.write.parquet(parqFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
