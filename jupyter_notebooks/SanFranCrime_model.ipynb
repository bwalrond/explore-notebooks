{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## San Francisco Crime Modeling\n",
    "\n",
    "Go here for the [details](https://www.kaggle.com/c/sf-crime) on the Kaggle competition\n",
    "\n",
    "### Predictive Goal:  \"Given time and location, you must predict the category of crime that occurred.\"\n",
    "\n",
    "Data profiling contained in a separate notebook (\"SanFranCrime.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7fed1c020390>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.setLogLevel('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset from the prepared Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878049\n",
      "root\n",
      " |-- Dates: timestamp (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Descript: string (nullable = true)\n",
      " |-- DayOfWeek: string (nullable = true)\n",
      " |-- PdDistrict: string (nullable = true)\n",
      " |-- Resolution: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- X: float (nullable = true)\n",
      " |-- Y: float (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "parqFileName = '/Users/bill.walrond/Documents/dsprj/data/SanFranCrime/train.pqt'\n",
    "sfc_train = sqlContext.read.parquet(parqFileName)\n",
    "print sfc_train.count()\n",
    "print sfc_train.printSchema()\n",
    "# sfc_train = sfc_train.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:  Establish and evaluate a baseline \n",
    "\n",
    "From the profiling results, the most frequent category of crime by far is \"LARCENY/THEFT\".  We can set our baseline prediction to assume every crime is LARCENY/THEFT regardless of the actual category or any of the other attributes.  Then, evaluate how accurate our baseline preditions are.  Later, we will compare how much better/worse the machine learning methods are compared to this baseline.\n",
    "\n",
    "For now, we're going to start with Precision-Recall for our evaluation framework.  Later, we may consider additional evaluation metrics (e.g. AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.199192\n",
      "Recall:  0.199192\n"
     ]
    }
   ],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"Category\", outputCol=\"indexedLabel\").fit(sfc_train)\n",
    "sfc_train_t = labelIndexer.transform(sfc_train)\n",
    "# sfc_train_t = sfc_train_t.cache()\n",
    "\n",
    "# baseline_preds = sfc_train_t.selectExpr('indexedLabel as prediction', 'double(0) as label')\n",
    "baseline_preds = sfc_train_t.selectExpr('indexedLabel as label', 'double(0) as prediction')\n",
    "baseline_preds = baseline_preds.cache()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction') \n",
    "evaluator.evaluate(baseline_preds) \n",
    "print 'Precision: {:08.6f}'.format(evaluator.evaluate(baseline_preds, {evaluator.metricName: 'precision'}))\n",
    "print 'Recall:  {:08.6f}'.format(evaluator.evaluate(baseline_preds, {evaluator.metricName: 'recall'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thus, our machine learning results must be better than guessing that every category is LARCENY/THEFT.\n",
    "\n",
    "### Todo:  program the LogLoss evaluation metric\n",
    "\n",
    "This is the multi-class version of the metric. Each observation is in one class and for each observation, you submit a predicted probability for each class. The metric is negative the log likelihood of the model that says each test observation is chosen independently from a distribution that places the submitted probability mass on the corresponding class, for each observation.\n",
    "\n",
    "$$log loss = -\\frac{1}{N}\\sum_{i=1}^N\\sum_{j=1}^My_{i,j}\\log(p_{i,j})$$\n",
    "\n",
    "where N is the number of observations, M is the number of class labels, \\\\(log\\\\) is the natural logarithm, \\\\(y_{i,j}\\\\) is 1 if observation \\\\(i\\\\) is in class \\\\(j\\\\) and 0 otherwise, and \\\\(p_{i,j}\\\\) is the predicted probability that observation \\\\(i\\\\) is in class \\\\(j\\\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeLogLoss(obs, classes, preds):\n",
    "    \n",
    "    sumM = 0.0\n",
    "    \n",
    "    for n in 1 to numberOfObs:   #  dataframe agg function\n",
    "        for m in 1 to numberOfClassLabels:   # map function\n",
    "            sumM += log(prob(n,m)) if actualLabel(n) == class(m) else 0.0\n",
    "    \n",
    "    logLoss = -(sumM/numberOfObs)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:  Prepare the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the categorical features ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878049\n",
      "root\n",
      " |-- Dates: timestamp (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Descript: string (nullable = true)\n",
      " |-- DayOfWeek: string (nullable = true)\n",
      " |-- PdDistrict: string (nullable = true)\n",
      " |-- Resolution: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- X: float (nullable = true)\n",
      " |-- Y: float (nullable = true)\n",
      " |-- DescriptIndex: double (nullable = true)\n",
      " |-- DescriptVec: vector (nullable = true)\n",
      " |-- DayOfWeekIndex: double (nullable = true)\n",
      " |-- DayOfWeekVec: vector (nullable = true)\n",
      " |-- PdDistrictIndex: double (nullable = true)\n",
      " |-- PdDistrictVec: vector (nullable = true)\n",
      " |-- ResolutionIndex: double (nullable = true)\n",
      " |-- ResolutionVec: vector (nullable = true)\n",
      " |-- AddressIndex: double (nullable = true)\n",
      " |-- AddressVec: vector (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "cols = ['Descript','DayOfWeek','PdDistrict','Resolution','Address']\n",
    "\n",
    "for col in cols:\n",
    "    stringIndexer = StringIndexer(inputCol=col, outputCol=col+'Index')\n",
    "    model = stringIndexer.fit(sfc_train)\n",
    "    sfc_train = model.transform(sfc_train)\n",
    "    encoder = OneHotEncoder(dropLast=False, inputCol=col+'Index', outputCol=col+'Vec')\n",
    "    sfc_train = encoder.transform(sfc_train)\n",
    "\n",
    "print sfc_train.count()\n",
    "print sfc_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+------------+--------------------+\n",
      "|Address                      |AddressIndex|AddressVec          |\n",
      "+-----------------------------+------------+--------------------+\n",
      "|VANNESS AV / GREENWICH ST    |7781.0      |(23228,[7781],[1.0])|\n",
      "|JEFFERSON ST / LEAVENWORTH ST|6049.0      |(23228,[6049],[1.0])|\n",
      "|MENDELL ST / HUDSON AV       |5846.0      |(23228,[5846],[1.0])|\n",
      "|2000 Block of BUSH ST        |3197.0      |(23228,[3197],[1.0])|\n",
      "|1600 Block of WEBSTER ST     |3081.0      |(23228,[3081],[1.0])|\n",
      "|0 Block of STOCKTON ST       |72.0        |(23228,[72],[1.0])  |\n",
      "|23RD ST / WISCONSIN ST       |4847.0      |(23228,[4847],[1.0])|\n",
      "|GEARY BL / LAGUNA ST         |246.0       |(23228,[246],[1.0]) |\n",
      "|400 Block of HYDE ST         |417.0       |(23228,[417],[1.0]) |\n",
      "|STOCKTON ST / SUTTER ST      |441.0       |(23228,[441],[1.0]) |\n",
      "+-----------------------------+------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sfc_train.select('Address','AddressIndex','AddressVec').show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we do about the \"Dates\" datetime column ?  ...\n",
    "\n",
    "\n",
    "Since we know from the data profiling results that the time span of the data is over 12 years, let's start with converting the Dates column to an ordinal (an integer value representing the number of days since year 1 day 1) and including with the VectorAssembler.  After that we'll try transforming the datetime value to year, month, day, day of month, hour of day, season, etc.  DayOfWeek is already provided separately in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---------+\n",
      "|Dates                |Dates_int|\n",
      "+---------------------+---------+\n",
      "|2015-05-13 23:33:00.0|735731   |\n",
      "|2015-05-13 22:58:00.0|735731   |\n",
      "|2015-05-13 21:40:00.0|735731   |\n",
      "+---------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "udfDateToordinal = udf(lambda dt: dt.toordinal(), LongType())\n",
    "sfc_train = sfc_train.withColumn('Dates_int',udfDateToordinal(sfc_train.Dates))\n",
    "print sfc_train.select('Dates','Dates_int').show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling the feature vector ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "|Category      |features                                                                                                         |\n",
      "+--------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "|OTHER OFFENSES|(24144,[0,45,881,889,898,8695,24142,24143],[735731.0,1.0,1.0,1.0,1.0,1.0,-122.42436218261719,37.8004150390625])  |\n",
      "|LARCENY/THEFT |(24144,[0,9,881,891,897,6963,24142,24143],[735731.0,1.0,1.0,1.0,1.0,1.0,-122.4190902709961,37.80780029296875])   |\n",
      "|OTHER OFFENSES|(24144,[0,11,881,890,898,6760,24142,24143],[735731.0,1.0,1.0,1.0,1.0,1.0,-122.38639831542969,37.738983154296875])|\n",
      "|LARCENY/THEFT |(24144,[0,1,881,889,897,4111,24142,24143],[735731.0,1.0,1.0,1.0,1.0,1.0,-122.43101501464844,37.78738784790039])  |\n",
      "|VANDALISM     |(24144,[0,13,881,889,897,3995,24142,24143],[735731.0,1.0,1.0,1.0,1.0,1.0,-122.43131256103516,37.78586959838867]) |\n",
      "+--------------+-----------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the VectorAssembler to combine the converted Dates column with the ...\n",
    "# Vectorized categorical column and also with the lat, long columns\n",
    "vector_cols = ['Dates_int'] + [name for name,type in sfc_train.dtypes if 'Vec' in name ] + ['X','Y']\n",
    "assembler = VectorAssembler(inputCols=vector_cols, outputCol=\"features\")\n",
    "sfc_train = assembler.transform(sfc_train)\n",
    "sfc_train.select('Category','features').show(5,truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trim down to just the columns we need then cache the dataframe, this will help to\n",
    "# keep the size of thw working dataset more manageable\n",
    "sfc_train_trimmed = sfc_train.select('Category','features')\n",
    "sfc_train_trimmed = sfc_train_trimmed.cache()\n",
    "\n",
    "# write the trimmed DF out to disk, then read it back in\n",
    "preppedFileName = '/Users/bill.walrond/Documents/dsprj/data/SanFranCrime/prepped.pqt'\n",
    "sfc_train_trimmed.write.parquet(preppedFileName, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878049\n",
      "root\n",
      " |-- Category: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# null out all our dataframes\n",
    "# preppedFileName = '/Users/bill.walrond/Documents/dsprj/data/SanFranCrime/prepped.pqt'\n",
    "preppedFileName = 's3n://caserta-bucket1/lab/SanFranCrime/prepped.pqt/'\n",
    "sfc_train = None\n",
    "predictions = None\n",
    "model = None\n",
    "encoder = None\n",
    "baseline_preds = None\n",
    "sqlContext.clearCache()\n",
    "\n",
    "prepped = sqlContext.read.parquet(preppedFileName)\n",
    "print prepped.count()\n",
    "print prepped.printSchema()\n",
    "prepped = prepped.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:  Create train and tune sets and fit a model\n",
    "\n",
    "### ToDo:  revise the splitting approach to be temporally aware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Category: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- indexedLabel: double (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n",
      "None\n",
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       0.0|        27.0|(24144,[0,179,880...|\n",
      "|       0.0|        27.0|(24144,[0,179,880...|\n",
      "|       0.0|        27.0|(24144,[0,179,880...|\n",
      "|       0.0|        27.0|(24144,[0,179,880...|\n",
      "|       0.0|        27.0|(24144,[0,179,880...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "if \"indexedLabel\" not in prepped.columns:\n",
    "    labelIndexer = StringIndexer(inputCol=\"Category\", outputCol=\"indexedLabel\").fit(prepped)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = prepped.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a GBT model.\n",
    "rf = RandomForestClassifier(labelCol='indexedLabel', featuresCol='features', \n",
    "                            # numTrees=30, \n",
    "                            numTrees=30, \n",
    "                            maxDepth=25,\n",
    "                            featureSubsetStrategy='auto')\n",
    "\n",
    "# Chain indexers and RF in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, rf])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions - returns a DataFrame\n",
    "predictions = model.transform(testData)\n",
    "print predictions.printSchema()\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "predictions = predictions.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|prediction| count|\n",
      "+----------+------+\n",
      "|       7.0| 11440|\n",
      "|      24.0|   437|\n",
      "|       1.0| 40479|\n",
      "|       9.0|  1614|\n",
      "|      12.0|   972|\n",
      "|      15.0|   263|\n",
      "|       6.0|  6373|\n",
      "|      20.0|    21|\n",
      "|       3.0| 15129|\n",
      "|      10.0|  4629|\n",
      "|      13.0|    39|\n",
      "|       5.0|  9493|\n",
      "|      16.0|   270|\n",
      "|      19.0|     1|\n",
      "|       8.0|   523|\n",
      "|      25.0|   490|\n",
      "|      28.0|    24|\n",
      "|      11.0|  1889|\n",
      "|       0.0|137460|\n",
      "|       4.0|  9964|\n",
      "+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = predictions.cache()\n",
    "# predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(10)\n",
    "predictions.select(\"prediction\").groupBy('prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.649101\n",
      "Recall:  0.649101\n"
     ]
    }
   ],
   "source": [
    "eval_preds = predictions.select('prediction','indexedLabel')\n",
    "eval_preds = eval_preds.cache()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='indexedLabel') \n",
    "evaluator.evaluate(eval_preds) \n",
    "print 'Precision: {:08.6f}'.format(evaluator.evaluate(eval_preds, {evaluator.metricName: 'precision'}))\n",
    "print 'Recall:  {:08.6f}'.format(evaluator.evaluate(eval_preds, {evaluator.metricName: 'recall'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# null out all our dataframes\n",
    "sfc_train = None\n",
    "predictions = None\n",
    "model = None\n",
    "encoder = None\n",
    "baseline_preds = None\n",
    "sqlContext.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
